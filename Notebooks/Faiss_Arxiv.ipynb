{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Faiss-Arxiv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa9d206279f14fb797a5813935f2de6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_993c929ad1794b4db32dd3566bad1d57",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee7ee06cbdf54063bfad1c39c186472f",
              "IPY_MODEL_4ac4678324f345559a633964a5d09680"
            ]
          }
        },
        "993c929ad1794b4db32dd3566bad1d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee7ee06cbdf54063bfad1c39c186472f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b3e1c26018048cca058b054152b0d92",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3664,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3664,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02877408b83944d6ab8062dd0c5d2c74"
          }
        },
        "4ac4678324f345559a633964a5d09680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81ef6525e6c44d4397cc2d70cefbe71a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3664/3664 [08:04&lt;00:00,  7.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_998aaaf4df7e40d1abd2e8c6472431eb"
          }
        },
        "5b3e1c26018048cca058b054152b0d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02877408b83944d6ab8062dd0c5d2c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81ef6525e6c44d4397cc2d70cefbe71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "998aaaf4df7e40d1abd2e8c6472431eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFAcQLx3uwNf"
      },
      "source": [
        "This notebook is used \n",
        " - to download the arxiv metadata \n",
        " - read the entire metadata and convert it into a dataframe\n",
        " - Save the dataframe in a csv in your google drive for future use and delete the metadata to free space \n",
        " - Filter out the five AI/ML categories \n",
        " - clean the latex formatted abstract and title columns \n",
        " - Instantiate the model, convert abstracts to vectors, and instantiate the faiss index with IndexFlatL2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ztWSLGvld69",
        "outputId": "fe8de465-b1a1-42d8-dd56-313492dbb73f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rb7PFbTmn6U"
      },
      "source": [
        " Have a closer look on the hardware spcifications, i.e. to get information about the installed CPU and GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApXk41C6msce",
        "outputId": "025c0353-5eae-4911-e846-28b007499a2b"
      },
      "source": [
        "!lscpu |grep 'Model name'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rZCA8Zsm38O",
        "outputId": "d91be8c6-7eed-43a3-dd71-193bfbd2783f"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-680d0840-aec8-a9b0-db95-2c6a8ca29a84)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9yNrW_dm-DV"
      },
      "source": [
        "In addition, you can check the available RAM and HDD memory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XQArD0Hm_F3",
        "outputId": "fe7bcc4c-dada-451f-b903-0ed89c1f4630"
      },
      "source": [
        "!cat /proc/meminfo | grep 'MemAvailable'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemAvailable:   12403728 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f4kBaHpnEIM",
        "outputId": "076c11da-bc44-4e0e-bac0-6eb9f306f944"
      },
      "source": [
        "!df -h / | awk '{print $4}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avail\n",
            "27G\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJspSY3qnIEc"
      },
      "source": [
        "Finally, one can execute the following command to get a live update on the GPU usage. This is useful to check how much of the GPU memory is in use to optimize the batchsize for training. Note that whenever the training routine in a notebook is still running, you need to execute this command in another Colaboratory notebook to get an instant response:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJJNP8CWnLSq",
        "outputId": "ad2165aa-ac8b-48aa-c7ff-bd4a470b446a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug  1 05:19:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzU-gSALn3Qb"
      },
      "source": [
        "### Download the arxiv meta data witg gsutil\n",
        "We will need gsutil utility from google cloud sdk. Firstly, you need to authenticate yourself in Colab. Once you run the code below, it will ask you to follow a link to login and enter an access token that you receive upon successful login.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6yQuCJoO1X"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9egkYkBUospA"
      },
      "source": [
        "We would be using the gsutil command to upload and download files. So we first need to install the GCloud SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mSf16d1urkV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLkv1a9EoUVx"
      },
      "source": [
        "!curl https://sdk.cloud.google.com | bash1\n",
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPr9tY4mpCik"
      },
      "source": [
        "### Download the json metadata from the cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y_NfKwopJ0R"
      },
      "source": [
        "!gsutil cp -n gs://arxiv-dataset/metadata-v5/arxiv-metadata-oai.json /content/gdrive/My\\ Drive/arxiv-metadata-oai.json\n",
        "!ls -l /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXPijB7vld7H"
      },
      "source": [
        "\n",
        "### Reading the entire json metadata\n",
        "This cell may take a minute to run considering the volume of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWMGfIYFld7H",
        "outputId": "9d7ab505-525d-4488-8319-a82ff1b78fe3"
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "import json\n",
        "\n",
        "input_file = \"/content/gdrive/MyDrive/Arxiv/arxiv-metadata-oai-snapshot.json\"\n",
        "\n",
        "data  = []\n",
        "with tqdm.tqdm(total=os.path.getsize(input_file)) as pbar:\n",
        "     with open(input_file, 'r') as f:\n",
        "          for line in f:\n",
        "              pbar.update(len(line))\n",
        "              data.append(json.loads(line))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3109294971/3109294971 [02:21<00:00, 21958727.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOZIJEBIld7N"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "data = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "oKoNvNaGugh3",
        "outputId": "6f12f8ae-d4c7-4820-80e8-e07216de411f"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>submitter</th>\n",
              "      <th>authors</th>\n",
              "      <th>title</th>\n",
              "      <th>comments</th>\n",
              "      <th>journal-ref</th>\n",
              "      <th>doi</th>\n",
              "      <th>report-no</th>\n",
              "      <th>categories</th>\n",
              "      <th>license</th>\n",
              "      <th>abstract</th>\n",
              "      <th>versions</th>\n",
              "      <th>update_date</th>\n",
              "      <th>authors_parsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0704.0001</td>\n",
              "      <td>Pavel Nadolsky</td>\n",
              "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
              "      <td>Calculation of prompt diphoton production cros...</td>\n",
              "      <td>37 pages, 15 figures; published version</td>\n",
              "      <td>Phys.Rev.D76:013009,2007</td>\n",
              "      <td>10.1103/PhysRevD.76.013009</td>\n",
              "      <td>ANL-HEP-PR-07-12</td>\n",
              "      <td>hep-ph</td>\n",
              "      <td>None</td>\n",
              "      <td>A fully differential calculation in perturba...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
              "      <td>2008-11-26</td>\n",
              "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0704.0002</td>\n",
              "      <td>Louis Theran</td>\n",
              "      <td>Ileana Streinu and Louis Theran</td>\n",
              "      <td>Sparsity-certifying Graph Decompositions</td>\n",
              "      <td>To appear in Graphs and Combinatorics</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>math.CO cs.CG</td>\n",
              "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
              "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
              "      <td>2008-12-13</td>\n",
              "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0704.0003</td>\n",
              "      <td>Hongjun Pan</td>\n",
              "      <td>Hongjun Pan</td>\n",
              "      <td>The evolution of the Earth-Moon system based o...</td>\n",
              "      <td>23 pages, 3 figures</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>physics.gen-ph</td>\n",
              "      <td>None</td>\n",
              "      <td>The evolution of Earth-Moon system is descri...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
              "      <td>2008-01-13</td>\n",
              "      <td>[[Pan, Hongjun, ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0704.0004</td>\n",
              "      <td>David Callan</td>\n",
              "      <td>David Callan</td>\n",
              "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
              "      <td>11 pages</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>math.CO</td>\n",
              "      <td>None</td>\n",
              "      <td>We show that a determinant of Stirling cycle...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
              "      <td>2007-05-23</td>\n",
              "      <td>[[Callan, David, ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0704.0005</td>\n",
              "      <td>Alberto Torchinsky</td>\n",
              "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
              "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
              "      <td>None</td>\n",
              "      <td>Illinois J. Math. 52 (2008) no.2, 681-689</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>math.CA math.FA</td>\n",
              "      <td>None</td>\n",
              "      <td>In this paper we show how to compute the $\\L...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
              "      <td>2013-10-15</td>\n",
              "      <td>[[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                     authors_parsed\n",
              "0  0704.0001  ...  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...\n",
              "1  0704.0002  ...           [[Streinu, Ileana, ], [Theran, Louis, ]]\n",
              "2  0704.0003  ...                                 [[Pan, Hongjun, ]]\n",
              "3  0704.0004  ...                                [[Callan, David, ]]\n",
              "4  0704.0005  ...  [[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MQBgpiHzeCw"
      },
      "source": [
        "Rename the id column to arxiv id and set the idex column as the id for easier manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ICbqZsLzOHS"
      },
      "source": [
        "data.rename(columns = {'id':'arxiv_id'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lWuMAIFzv5b",
        "outputId": "88a87a59-bef8-4934-e5c7-f86ab410ed81"
      },
      "source": [
        "print(data.index.name)\n",
        "data.index.name = 'id'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CRIKZyM0Rlm"
      },
      "source": [
        "data.reset_index(level=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lMn4vbvj2aiB",
        "outputId": "48263783-3141-4b12-e228-8bcd95e9a221"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>arxiv_id</th>\n",
              "      <th>submitter</th>\n",
              "      <th>authors</th>\n",
              "      <th>title</th>\n",
              "      <th>comments</th>\n",
              "      <th>journal-ref</th>\n",
              "      <th>doi</th>\n",
              "      <th>report-no</th>\n",
              "      <th>categories</th>\n",
              "      <th>license</th>\n",
              "      <th>abstract</th>\n",
              "      <th>versions</th>\n",
              "      <th>update_date</th>\n",
              "      <th>authors_parsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0704.0001</td>\n",
              "      <td>Pavel Nadolsky</td>\n",
              "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
              "      <td>Calculation of prompt diphoton production cros...</td>\n",
              "      <td>37 pages, 15 figures; published version</td>\n",
              "      <td>Phys.Rev.D76:013009,2007</td>\n",
              "      <td>10.1103/PhysRevD.76.013009</td>\n",
              "      <td>ANL-HEP-PR-07-12</td>\n",
              "      <td>hep-ph</td>\n",
              "      <td>None</td>\n",
              "      <td>A fully differential calculation in perturba...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
              "      <td>2008-11-26</td>\n",
              "      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0704.0002</td>\n",
              "      <td>Louis Theran</td>\n",
              "      <td>Ileana Streinu and Louis Theran</td>\n",
              "      <td>Sparsity-certifying Graph Decompositions</td>\n",
              "      <td>To appear in Graphs and Combinatorics</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>math.CO cs.CG</td>\n",
              "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
              "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
              "      <td>2008-12-13</td>\n",
              "      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0704.0003</td>\n",
              "      <td>Hongjun Pan</td>\n",
              "      <td>Hongjun Pan</td>\n",
              "      <td>The evolution of the Earth-Moon system based o...</td>\n",
              "      <td>23 pages, 3 figures</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>physics.gen-ph</td>\n",
              "      <td>None</td>\n",
              "      <td>The evolution of Earth-Moon system is descri...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
              "      <td>2008-01-13</td>\n",
              "      <td>[[Pan, Hongjun, ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0704.0004</td>\n",
              "      <td>David Callan</td>\n",
              "      <td>David Callan</td>\n",
              "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
              "      <td>11 pages</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>math.CO</td>\n",
              "      <td>None</td>\n",
              "      <td>We show that a determinant of Stirling cycle...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
              "      <td>2007-05-23</td>\n",
              "      <td>[[Callan, David, ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0704.0005</td>\n",
              "      <td>Alberto Torchinsky</td>\n",
              "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
              "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
              "      <td>None</td>\n",
              "      <td>Illinois J. Math. 52 (2008) no.2, 681-689</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>math.CA math.FA</td>\n",
              "      <td>None</td>\n",
              "      <td>In this paper we show how to compute the $\\L...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
              "      <td>2013-10-15</td>\n",
              "      <td>[[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0704.0006</td>\n",
              "      <td>Yue Hin Pong</td>\n",
              "      <td>Y. H. Pong and C. K. Law</td>\n",
              "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
              "      <td>6 pages, 4 figures, accepted by PRA</td>\n",
              "      <td>None</td>\n",
              "      <td>10.1103/PhysRevA.75.043613</td>\n",
              "      <td>None</td>\n",
              "      <td>cond-mat.mes-hall</td>\n",
              "      <td>None</td>\n",
              "      <td>We study the two-particle wave function of p...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
              "      <td>2015-05-13</td>\n",
              "      <td>[[Pong, Y. H., ], [Law, C. K., ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0704.0007</td>\n",
              "      <td>Alejandro Corichi</td>\n",
              "      <td>Alejandro Corichi, Tatjana Vukasinac and Jose ...</td>\n",
              "      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n",
              "      <td>16 pages, no figures. Typos corrected to match...</td>\n",
              "      <td>Phys.Rev.D76:044016,2007</td>\n",
              "      <td>10.1103/PhysRevD.76.044016</td>\n",
              "      <td>IGPG-07/03-2</td>\n",
              "      <td>gr-qc</td>\n",
              "      <td>None</td>\n",
              "      <td>A rather non-standard quantum representation...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
              "      <td>2008-11-26</td>\n",
              "      <td>[[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0704.0008</td>\n",
              "      <td>Damian Swift</td>\n",
              "      <td>Damian C. Swift</td>\n",
              "      <td>Numerical solution of shock and ramp compressi...</td>\n",
              "      <td>Minor corrections</td>\n",
              "      <td>Journal of Applied Physics, vol 104, 073536 (2...</td>\n",
              "      <td>10.1063/1.2975338</td>\n",
              "      <td>LA-UR-07-2051, LLNL-JRNL-410358</td>\n",
              "      <td>cond-mat.mtrl-sci</td>\n",
              "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
              "      <td>A general formulation was developed to repre...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
              "      <td>2009-02-05</td>\n",
              "      <td>[[Swift, Damian C., ]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0704.0009</td>\n",
              "      <td>Paul Harvey</td>\n",
              "      <td>Paul Harvey, Bruno Merin, Tracy L. Huard, Luis...</td>\n",
              "      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n",
              "      <td>None</td>\n",
              "      <td>Astrophys.J.663:1149-1173,2007</td>\n",
              "      <td>10.1086/518646</td>\n",
              "      <td>None</td>\n",
              "      <td>astro-ph</td>\n",
              "      <td>None</td>\n",
              "      <td>We discuss the results from the combined IRA...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
              "      <td>2010-03-18</td>\n",
              "      <td>[[Harvey, Paul, ], [Merin, Bruno, ], [Huard, T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0704.0010</td>\n",
              "      <td>Sergei Ovchinnikov</td>\n",
              "      <td>Sergei Ovchinnikov</td>\n",
              "      <td>Partial cubes: structures, characterizations, ...</td>\n",
              "      <td>36 pages, 17 figures</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>math.CO</td>\n",
              "      <td>None</td>\n",
              "      <td>Partial cubes are isometric subgraphs of hyp...</td>\n",
              "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
              "      <td>2007-05-23</td>\n",
              "      <td>[[Ovchinnikov, Sergei, ]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id   arxiv_id  ... update_date                                     authors_parsed\n",
              "0   0  0704.0001  ...  2008-11-26  [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...\n",
              "1   1  0704.0002  ...  2008-12-13           [[Streinu, Ileana, ], [Theran, Louis, ]]\n",
              "2   2  0704.0003  ...  2008-01-13                                 [[Pan, Hongjun, ]]\n",
              "3   3  0704.0004  ...  2007-05-23                                [[Callan, David, ]]\n",
              "4   4  0704.0005  ...  2013-10-15  [[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]\n",
              "5   5  0704.0006  ...  2015-05-13                  [[Pong, Y. H., ], [Law, C. K., ]]\n",
              "6   6  0704.0007  ...  2008-11-26  [[Corichi, Alejandro, ], [Vukasinac, Tatjana, ...\n",
              "7   7  0704.0008  ...  2009-02-05                             [[Swift, Damian C., ]]\n",
              "8   8  0704.0009  ...  2010-03-18  [[Harvey, Paul, ], [Merin, Bruno, ], [Huard, T...\n",
              "9   9  0704.0010  ...  2007-05-23                          [[Ovchinnikov, Sergei, ]]\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOPbXpc7K-pb"
      },
      "source": [
        "Save the csv as there is a lot of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ceX9P-LIuIO"
      },
      "source": [
        "data.to_csv(\"/content/gdrive/MyDrive/Arxiv/Arxiv_Full.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2uQfEQuxGZa"
      },
      "source": [
        "Factory reset the runtime to clear the ram.<br>\n",
        "Upload the requirements.txt file in notebooks folder in the repo <br>\n",
        "Mount the drive again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGjbfunlO2yZ",
        "outputId": "cd2312c9-097d-474c-fc8e-3d2335e081b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y-HGzjITzgzC",
        "outputId": "35bc4773-da24-42d9-c4b1-a1acaceeeb84"
      },
      "source": [
        "!pip install -r /content/gdrive/MyDrive/Arxiv/requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.7 kB/s \n",
            "\u001b[?25hCollecting transformers==3.3.1\n",
            "  Downloading transformers-3.3.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.4 MB/s \n",
            "\u001b[?25hCollecting sentence-transformers==0.3.8\n",
            "  Downloading sentence-transformers-0.3.8.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting pandas==1.1.2\n",
            "  Downloading pandas-1.1.2-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 13.4 MB/s \n",
            "\u001b[?25hCollecting faiss-cpu==1.6.1\n",
            "  Downloading faiss_cpu-1.6.1-cp37-cp37m-manylinux2010_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 21.1 MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.2\n",
            "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 29 kB/s \n",
            "\u001b[?25hCollecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting streamlit==0.62.0\n",
            "  Downloading streamlit-0.62.0-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (4.41.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 64.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.8->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 3)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.8->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.8->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.2->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.2->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 7)) (2.11.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (7.1.2)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 72.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (1.5.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (3.17.3)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.11-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 56.7 MB/s \n",
            "\u001b[?25hCollecting botocore>=1.13.44\n",
            "  Downloading botocore-1.21.11-py3-none-any.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 36.8 MB/s \n",
            "\u001b[?25hCollecting base58\n",
            "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (4.1.0)\n",
            "Collecting validators\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.8.1)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.6.2-py2.py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 61.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.10.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (4.2.2)\n",
            "Collecting enum-compat\n",
            "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (7.1.2)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-2.1.3-py3-none-manylinux2014_x86_64.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (5.1.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (2.6.0)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.0->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (5.0.5)\n",
            "Collecting ipykernel>=5.1.2\n",
            "  Downloading ipykernel-6.0.3-py3-none-any.whl (122 kB)\n",
            "\u001b[K     |████████████████████████████████| 122 kB 73.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (7.6.3)\n",
            "Collecting importlib-metadata<4\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting ipython<8.0,>=7.23.1\n",
            "  Downloading ipython-7.26.0-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-client<7.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (5.3.5)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.1.2)\n",
            "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.18.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (4.4.2)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.19-py3-none-any.whl (368 kB)\n",
            "\u001b[K     |████████████████████████████████| 368 kB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (57.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 7)) (2.0.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (22.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (4.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.10.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (1.7.1)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.62.0->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 8)) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (2.4.7)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1->-r /content/gdrive/MyDrive/Arxiv/requirements.txt (line 2)) (1.0.1)\n",
            "Building wheels for collected packages: sentence-transformers, folium, blinker\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.8-py3-none-any.whl size=101996 sha256=1d7269579c6b481dc5cf6fcc0fbb4cd743e7523037e0ee67fb57f192193fc1d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/43/65/fe0f3ea9327623e749a79eb5dfad85a809c84064b1cc4682c1\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79808 sha256=2e654b05d74eecf304e8729e19882c66696449aefd8dc33def9d252f6479abb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/f0/3a/3f79a6914ff5affaf50cabad60c9f4d565283283c97f0bdccf\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13479 sha256=54787053d7e49dcc265004e81af1fb76edc76868347bfe9976f8c0ee04aa016b\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
            "Successfully built sentence-transformers folium blinker\n",
            "Installing collected packages: prompt-toolkit, ipython, importlib-metadata, ipykernel, urllib3, jmespath, numpy, botocore, tokenizers, sentencepiece, sacremoses, s3transfer, pandas, watchdog, validators, transformers, torch, pydeck, enum-compat, boto3, blinker, base58, streamlit, sentence-transformers, folium, faiss-cpu\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.1\n",
            "    Uninstalling importlib-metadata-4.6.1:\n",
            "      Successfully uninstalled importlib-metadata-4.6.1\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: folium\n",
            "    Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.19 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.26.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed base58-2.1.0 blinker-1.4 boto3-1.18.11 botocore-1.21.11 enum-compat-0.0.3 faiss-cpu-1.6.1 folium-0.2.1 importlib-metadata-3.10.1 ipykernel-6.0.3 ipython-7.26.0 jmespath-0.10.0 numpy-1.19.2 pandas-1.1.2 prompt-toolkit-3.0.19 pydeck-0.6.2 s3transfer-0.5.0 sacremoses-0.0.45 sentence-transformers-0.3.8 sentencepiece-0.1.96 streamlit-0.62.0 tokenizers-0.8.1rc2 torch-1.8.1 transformers-3.3.1 urllib3-1.25.11 validators-0.18.2 watchdog-2.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "ipykernel",
                  "numpy",
                  "pandas",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmMtolXvMv7h"
      },
      "source": [
        "Read from the csv and delete the arxiv json metadata if required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knBgbJYsM4kl",
        "outputId": "7926af75-4626-450c-8023-1d3aab89f606"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/Arxiv/Arxiv_Full.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  \"\"\"A safe version of the builtin execfile().\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVlhRq9reTjl"
      },
      "source": [
        "#Filter out the Five AI/ML categories\n",
        "# cs.CL => Computation and Language\n",
        "# cs.IR => Information Retrieval\n",
        "# cs.LG => Machine Learning\n",
        "# cs.HC => Human-Computer Interaction\n",
        "# cs.CV => Computer Vision and Pattern Recognition\n",
        "ai_ml_df = df[df.categories.str.match('cs.CL|cs.IR|cs.LG|cs.HC|cs.CV')]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCzWwkYb1fDb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def vector_search(query, model, index, num_results=10):\n",
        "    \"\"\"Tranforms query to vector using a pretrained, sentence-level\n",
        "    DistilBERT model and finds similar vectors using FAISS.\n",
        "    Args:\n",
        "        query (str): User query that should be more than a sentence long.\n",
        "        model (sentence_transformers.SentenceTransformer.SentenceTransformer)\n",
        "        index (`numpy.ndarray`): FAISS index that needs to be deserialized.\n",
        "        num_results (int): Number of results to return.\n",
        "    Returns:\n",
        "        D (:obj:`numpy.array` of `float`): Distance between results and query.\n",
        "        I (:obj:`numpy.array` of `int`): Paper ID of the results.\n",
        "\n",
        "    \"\"\"\n",
        "    vector = model.encode(list(query))\n",
        "    D, I = index.search(np.array(vector).astype(\"float32\"), k=num_results)\n",
        "    return D, I\n",
        "\n",
        "\n",
        "def id2details(df, I, column):\n",
        "    \"\"\"Returns the paper titles based on the paper index.\"\"\"\n",
        "    return [list(df[df.id == idx][column]) for idx in I[0]]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUKVHpJqN5kv",
        "outputId": "34aea6d2-3e58-4211-8a6b-84d1b68d496b"
      },
      "source": [
        "ai_ml_df.dtypes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 int64\n",
              "arxiv_id          object\n",
              "submitter         object\n",
              "authors           object\n",
              "title             object\n",
              "comments          object\n",
              "journal-ref       object\n",
              "doi               object\n",
              "report-no         object\n",
              "categories        object\n",
              "license           object\n",
              "abstract          object\n",
              "versions          object\n",
              "update_date       object\n",
              "authors_parsed    object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUl1t0IIXrND",
        "outputId": "97cf6b28-42a7-4b43-fbda-411efbfb6646"
      },
      "source": [
        "!pip install pylatexenc"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pylatexenc in /usr/local/lib/python3.7/dist-packages (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W3ThD1xXGF0",
        "outputId": "78af6c79-2e7c-4914-b816-fbe1022b74fd"
      },
      "source": [
        "# We will transform both the title and abstract text to UTF-8 format using the pylatexenc library\n",
        "from pylatexenc.latex2text import LatexNodes2Text\n",
        "\n",
        "# LaTex to UTF\n",
        "clean_abstract = []\n",
        "clean_title = []\n",
        "for i,a in ai_ml_df.iterrows():\n",
        "    # Clean title\n",
        "    try:\n",
        "        clean_title.append(LatexNodes2Text().latex_to_text(a['title']).replace('\\n', ' ').strip()) \n",
        "    except:\n",
        "        clean_title.append(a['abstract'].replace('\\n', ' ').strip())\n",
        "    # Clean abstract\n",
        "    try:\n",
        "        clean_abstract.append(LatexNodes2Text().latex_to_text(a['abstract']).replace('\\n', ' ').strip()) \n",
        "    except:\n",
        "        clean_abstract.append(a['abstract'].replace('\\n', ' ').strip())\n",
        "ai_ml_df['clean_abstracts'] = clean_abstract\n",
        "ai_ml_df['clean_title'] = clean_title"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Error in configuration: macro '\\frac' failed its substitution!\n",
            "WARNING: Error in configuration: macro '\\frac' failed its substitution!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF4BsrV7UO35"
      },
      "source": [
        "ai_ml_df.to_csv('/content/gdrive/MyDrive/Arxiv/Arxiv_AIML_processed.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu3m6LF9_JgG",
        "outputId": "72c14d8d-9f0e-4f56-be37-c19161250489"
      },
      "source": [
        "print(f\"Arxiv articles:{ai_ml_df.id.unique().shape[0]}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arxiv articles:117234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i8TlEp_A7mv"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Used to create the dense document vectors.\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Used to create and store the Faiss index.\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pathlib import Path"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N7JmC9F_TM-",
        "outputId": "c82fa442-b7f9-42ee-a190-83e16d8aad21"
      },
      "source": [
        "# Instantiate the sentence-level DistilBERT\n",
        "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
        "# Check if GPU is available and use it\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to(torch.device(\"cuda\"))\n",
        "print(model.device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245M/245M [00:16<00:00, 14.4MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "aa9d206279f14fb797a5813935f2de6c",
            "993c929ad1794b4db32dd3566bad1d57",
            "ee7ee06cbdf54063bfad1c39c186472f",
            "4ac4678324f345559a633964a5d09680",
            "5b3e1c26018048cca058b054152b0d92",
            "02877408b83944d6ab8062dd0c5d2c74",
            "81ef6525e6c44d4397cc2d70cefbe71a",
            "998aaaf4df7e40d1abd2e8c6472431eb"
          ]
        },
        "id": "L7qPtO-NEtus",
        "outputId": "39c632ce-af33-4000-af8f-7a857ac15bb1"
      },
      "source": [
        "# Convert abstracts to vectors\n",
        "embeddings = model.encode(ai_ml_df.clean_abstracts.to_list(), show_progress_bar=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa9d206279f14fb797a5813935f2de6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=3664.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4PnIk8oGrWj",
        "outputId": "285c6cb2-02de-4287-f741-3e9109305303"
      },
      "source": [
        "print(f'Shape of the vectorised abstract: {embeddings[0].shape}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the vectorised abstract: (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3mhoLiiG355",
        "outputId": "53dbeb77-2ea1-48a4-b652-c8cb17d498ba"
      },
      "source": [
        "# Step 1: Change data type\n",
        "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")\n",
        "\n",
        "# Step 2: Instantiate the index\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "\n",
        "# Step 3: Pass the index to IndexIDMap\n",
        "index = faiss.IndexIDMap(index)\n",
        "\n",
        "#convert id to int64\n",
        "ids = np.asarray(ai_ml_df.id.astype('int64'))\n",
        "print(ids)\n",
        "# Step 4: Add vectors and their IDs\n",
        "index.add_with_ids(embeddings, ids)\n",
        "\n",
        "print(f\"Number of vectors in the Faiss index: {index.ntotal}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1019    1027    1266 ... 1665369 1665376 1665377]\n",
            "Number of vectors in the Faiss index: 117234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "zEND-ym6If-E",
        "outputId": "942af56a-71a1-4ff7-d646-0ee0bb418d5e"
      },
      "source": [
        "ai_ml_df.iloc[5415, 15]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Three-dimensional particle tracking is an essential tool in studying dynamics under the microscope, namely, fluid dynamics in microfluidic devices, bacteria taxis, cellular trafficking. The 3d position can be determined using 2d imaging alone by measuring the diffraction rings generated by an out-of-focus fluorescent particle, imaged on a single camera. Here I present a ring detection algorithm exhibiting a high detection rate, which is robust to the challenges arising from ring occlusion, inclusions and overlaps, and allows resolving particles even when near to each other. It is capable of real time analysis thanks to its high performance and low memory footprint. The proposed algorithm, an offspring of the circle Hough transform, addresses the need to efficiently trace the trajectories of many particles concurrently, when their number in not necessarily fixed, by solving a classification problem, and overcomes the challenges of finding local maxima in the complex parameter space which results from ring clusters and noise. Several algorithmic concepts introduced here can be advantageous in other cases, particularly when dealing with noisy and sparse data. The implementation is based on open-source and cross-platform software packages only, making it easy to distribute and modify. It is implemented in a microfluidic experiment allowing real-time multi-particle tracking at 70 Hz, achieving a detection rate which exceeds 94 and only 1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoeg44phJDiy",
        "outputId": "c56d191f-88ff-4d4e-c5b9-b98682717664"
      },
      "source": [
        "# Retrieve the 10 nearest neighbours\n",
        "D, I = index.search(np.array([embeddings[5415]]), k=10)\n",
        "print(f'L2 distance: {D.flatten().tolist()}\\n\\nArxiv paper IDs: {I.flatten().tolist()}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2 distance: [0.0, 68.53523254394531, 70.18161010742188, 72.04075622558594, 73.01589965820312, 75.42435455322266, 76.07571411132812, 76.50065612792969, 77.51425170898438, 77.761962890625]\n",
            "\n",
            "Arxiv paper IDs: [466374, 1457933, 1660222, 1105598, 1481269, 1017831, 622208, 1038120, 389291, 1135725]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLguTqS5Jgqj",
        "outputId": "103fb1ea-4c5a-4448-8350-eedd7a07a832"
      },
      "source": [
        "# Fetch the paper titles based on their index\n",
        "id2details(ai_ml_df, I, 'clean_title')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Robust and highly performant ring detection algorithm for 3d particle   tracking using 2d microscope imaging'],\n",
              " ['Real-time dense 3D Reconstruction from monocular video data captured by   low-cost UAVs'],\n",
              " ['Camera Calibration: a USU Implementation'],\n",
              " ['Defogging Kinect: Simultaneous Estimation of Object Region and Depth in   Foggy Scenes'],\n",
              " ['Self-supervised Depth Estimation Leveraging Global Perception and   Geometric Smoothness Using On-board Videos'],\n",
              " ['HMS-Net: Hierarchical Multi-scale Sparsity-invariant Network for Sparse   Depth Completion'],\n",
              " ['Noise in Structured-Light Stereo Depth Cameras: Modeling and its   Applications'],\n",
              " ['CNN-based Preprocessing to Optimize Watershed-based Cell Segmentation in   3D Confocal Microscopy Images'],\n",
              " ['Orientation Determination from Cryo-EM images Using Least Unsquared   Deviation'],\n",
              " ['Structure from Motion for Panorama-Style Videos']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5lPdqJ0ckFR",
        "outputId": "10b8510c-cd18-4473-8a1e-15da7b2b0b97"
      },
      "source": [
        "id2details(ai_ml_df, I, 'clean_abstracts')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Three-dimensional particle tracking is an essential tool in studying dynamics under the microscope, namely, fluid dynamics in microfluidic devices, bacteria taxis, cellular trafficking. The 3d position can be determined using 2d imaging alone by measuring the diffraction rings generated by an out-of-focus fluorescent particle, imaged on a single camera. Here I present a ring detection algorithm exhibiting a high detection rate, which is robust to the challenges arising from ring occlusion, inclusions and overlaps, and allows resolving particles even when near to each other. It is capable of real time analysis thanks to its high performance and low memory footprint. The proposed algorithm, an offspring of the circle Hough transform, addresses the need to efficiently trace the trajectories of many particles concurrently, when their number in not necessarily fixed, by solving a classification problem, and overcomes the challenges of finding local maxima in the complex parameter space which results from ring clusters and noise. Several algorithmic concepts introduced here can be advantageous in other cases, particularly when dealing with noisy and sparse data. The implementation is based on open-source and cross-platform software packages only, making it easy to distribute and modify. It is implemented in a microfluidic experiment allowing real-time multi-particle tracking at 70 Hz, achieving a detection rate which exceeds 94 and only 1'],\n",
              " ['Real-time 3D reconstruction enables fast dense mapping of the environment which benefits numerous applications, such as navigation or live evaluation of an emergency. In contrast to most real-time capable approaches, our approach does not need an explicit depth sensor. Instead, we only rely on a video stream from a camera and its intrinsic calibration. By exploiting the self-motion of the unmanned aerial vehicle (UAV) flying with oblique view around buildings, we estimate both camera trajectory and depth for selected images with enough novel content. To create a 3D model of the scene, we rely on a three-stage processing chain. First, we estimate the rough camera trajectory using a simultaneous localization and mapping (SLAM) algorithm. Once a suitable constellation is found, we estimate depth for local bundles of images using a Multi-View Stereo (MVS) approach and then fuse this depth into a global surfel-based model. For our evaluation, we use 55 video sequences with diverse settings, consisting of both synthetic and real scenes. We evaluate not only the generated reconstruction but also the intermediate products and achieve competitive results both qualitatively and quantitatively. At the same time, our method can keep up with a 30 fps video for a resolution of 768x448 pixels.'],\n",
              " ['The task of camera calibration is to estimate the intrinsic and extrinsic parameters of a camera model. Though there are some restricted techniques to infer the 3-D information about the scene from uncalibrated cameras, effective camera calibration procedures will open up the possibility of using a wide range of existing algorithms for 3-D reconstruction and recognition.   The applications of camera calibration include vision-based metrology, robust visual platooning and visual docking of mobile robots where the depth information is important.'],\n",
              " ['Three-dimensional (3D) reconstruction and scene depth estimation from 2-dimensional (2D) images are major tasks in computer vision. However, using conventional 3D reconstruction techniques gets challenging in participating media such as murky water, fog, or smoke. We have developed a method that uses a time-of-flight (ToF) camera to estimate an object region and depth in participating media simultaneously. The scattering component is saturated, so it does not depend on the scene depth, and received signals bouncing off distant points are negligible due to light attenuation in the participating media, so the observation of such a point contains only a scattering component. These phenomena enable us to estimate the scattering component in an object region from a background that only contains the scattering component. The problem is formulated as robust estimation where the object region is regarded as outliers, and it enables the simultaneous estimation of an object region and depth on the basis of an iteratively reweighted least squares (IRLS) optimization scheme. We demonstrate the effectiveness of the proposed method using captured images from a Kinect v2 in real foggy scenes and evaluate the applicability with synthesized data.'],\n",
              " ['Self-supervised depth estimation has drawn much attention in recent years as it does not require labeled data but image sequences. Moreover, it can be conveniently used in various applications, such as autonomous driving, robotics, realistic navigation, and smart cities. However, extracting global contextual information from images and predicting a geometrically natural depth map remain challenging. In this paper, we present DLNet for pixel-wise depth estimation, which simultaneously extracts global and local features with the aid of our depth Linformer block. This block consists of the Linformer and innovative soft split multi-layer perceptron blocks. Moreover, a three-dimensional geometry smoothness loss is proposed to predict a geometrically natural depth map by imposing the second-order smoothness constraint on the predicted three-dimensional point clouds, thereby realizing improved performance as a byproduct. Finally, we explore the multi-scale prediction strategy and propose the maximum margin dual-scale prediction strategy for further performance improvement. In experiments on the KITTI and Make3D benchmarks, the proposed DLNet achieves performance competitive to those of the state-of-the-art methods, reducing time and space complexities by more than 62% and 56%, respectively. Extensive testing on various real-world situations further demonstrates the strong practicality and generalization capability of the proposed model.'],\n",
              " ['Dense depth cues are important and have wide applications in various computer vision tasks. In autonomous driving, LIDAR sensors are adopted to acquire depth measurements around the vehicle to perceive the surrounding environments. However, depth maps obtained by LIDAR are generally sparse because of its hardware limitation. The task of depth completion attracts increasing attention, which aims at generating a dense depth map from an input sparse depth map. To effectively utilize multi-scale features, we propose three novel sparsity-invariant operations, based on which, a sparsity-invariant multi-scale encoder-decoder network (HMS-Net) for handling sparse inputs and sparse feature maps is also proposed. Additional RGB features could be incorporated to further improve the depth completion performance. Our extensive experiments and component analysis on two public benchmarks, KITTI depth completion benchmark and NYU-depth-v2 dataset, demonstrate the effectiveness of the proposed approach. As of Aug. 12th, 2018, on KITTI depth completion leaderboard, our proposed model without RGB guidance ranks first among all peer-reviewed methods without using RGB information, and our model with RGB guidance ranks second among all RGB-guided methods.'],\n",
              " ['Depth maps obtained from commercially available structured-light stereo based depth cameras, such as the Kinect, are easy to use but are affected by significant amounts of noise. This paper is devoted to a study of the intrinsic noise characteristics of such depth maps, i.e. the standard deviation of noise in estimated depth varies quadratically with the distance of the object from the depth camera. We validate this theoretical model against empirical observations and demonstrate the utility of this noise model in three popular applications: depth map denoising, volumetric scan merging for 3D modeling, and identification of 3D planes in depth maps.'],\n",
              " ['The quantitative analysis of cellular membranes helps understanding developmental processes at the cellular level. Particularly 3D microscopic image data offers valuable insights into cell dynamics, but error-free automatic segmentation remains challenging due to the huge amount of data generated and strong variations in image intensities. In this paper, we propose a new 3D segmentation approach which combines the discriminative power of convolutional neural networks (CNNs) for preprocessing and investigates the performance of three watershed-based postprocessing strategies (WS), which are well suited to segment object shapes, even when supplied with vague seed and boundary constraints. To leverage the full potential of the watershed algorithm, the multi-instance segmentation problem is initially interpreted as three-class semantic segmentation problem, which in turn is well-suited for the application of CNNs. Using manually annotated 3D confocal microscopy images of Arabidopsis thaliana, we show the superior performance of the proposed method compared to the state of the art.'],\n",
              " ['A major challenge in single particle reconstruction from cryo-electron microscopy is to establish a reliable ab-initio three-dimensional model using two-dimensional projection images with unknown orientations. Common-lines based methods estimate the orientations without additional geometric information. However, such methods fail when the detection rate of common-lines is too low due to the high level of noise in the images. An approximation to the least squares global self consistency error was obtained using convex relaxation by semidefinite programming. In this paper we introduce a more robust global self consistency error and show that the corresponding optimization problem can be solved via semidefinite relaxation. In order to prevent artificial clustering of the estimated viewing directions, we further introduce a spectral norm term that is added as a constraint or as a regularization term to the relaxed minimization problem. The resulted problems are solved by using either the alternating direction method of multipliers or an iteratively reweighted least squares procedure. Numerical experiments with both simulated and real images demonstrate that the proposed methods significantly reduce the orientation estimation error when the detection rate of common-lines is low.'],\n",
              " ['We present a novel Structure from Motion pipeline that is capable of reconstructing accurate camera poses for panorama-style video capture without prior camera intrinsic calibration. While panorama-style capture is common and convenient, previous reconstruction methods fail to obtain accurate reconstructions due to the rotation-dominant motion and small baseline between views. Our method is built on the assumption that the camera motion approximately corresponds to motion on a sphere, and we introduce three novel relative pose methods to estimate the fundamental matrix and camera distortion for spherical motion. These solvers are efficient and robust, and provide an excellent initialization for bundle adjustment. A soft prior on the camera poses is used to discourage large deviations from the spherical motion assumption when performing bundle adjustment, which allows cameras to remain properly constrained for optimization in the absence of well-triangulated 3D points. To validate the effectiveness of the proposed method we evaluate our approach on both synthetic and real-world data, and demonstrate that camera poses are accurate enough for multiview stereo.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJdqNbHoc0IZ"
      },
      "source": [
        "##Putting all together\n",
        "So far, we've built a Faiss index using the misinformation abstract vectors we encoded with a sentence-DistilBERT model. That's helpful but in a real case scenario, we would have to work with unseen data. To query the index with an unseen query and retrieve its most relevant documents, we would have to do the following:\n",
        "\n",
        "Encode the query with the same sentence-DistilBERT model we used for the rest of the abstract vectors.\n",
        "Change its data type to float32.\n",
        "Search the index with the encoded query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alVEeZjRcpsT"
      },
      "source": [
        "user_query = \"\"\"\n",
        "This paper describes an efficient reduction of the learning problem of\n",
        "ranking to binary classification. The reduction guarantees an average pairwise\n",
        "misranking regret of at most that of the binary classifier regret, improving a\n",
        "recent result of Balcan et al which only guarantees a factor of 2. Moreover,\n",
        "our reduction applies to a broader class of ranking loss functions, admits a\n",
        "simpler proof, and the expected running time complexity of our algorithm in\n",
        "terms of number of calls to a classifier or preference function is improved\n",
        "from $\\Omega(n^2)$ to $O(n \\log n)$. In addition, when the top $k$ ranked\n",
        "elements only are required ($k \\ll n$), as in many applications in information\n",
        "extraction or search engines, the time complexity of our algorithm can be\n",
        "further reduced to $O(k \\log k + n)$. Our reduction and algorithm are thus\n",
        "practical for realistic applications where the number of points to rank exceeds\n",
        "several thousands. Much of our results also extend beyond the bipartite case\n",
        "previously studied.\n",
        "Our rediction is a randomized one. To complement our result, we also derive\n",
        "lower bounds on any deterministic reduction from binary (preference)\n",
        "classification to ranking, implying that our use of a randomized reduction is\n",
        "essentially necessary for the guarantees we provide.\n",
        "\"\"\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4C8vP7WjsBt",
        "outputId": "148a965a-301a-4e01-fac2-13d00e59ecfa"
      },
      "source": [
        "# For convenience, I've wrapped all steps in the vector_search function.\n",
        "# It takes four arguments: \n",
        "# A query, the sentence-level transformer, the Faiss index and the number of requested results\n",
        "D, I = vector_search([user_query], model, index, num_results=10)\n",
        "print(f'L2 distance: {D.flatten().tolist()}\\n\\nArxiv paper IDs: {I.flatten().tolist()}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2 distance: [5.541277885437012, 55.357948303222656, 62.93092346191406, 67.29206848144531, 68.80670166015625, 70.92662048339844, 72.32435607910156, 74.47453308105469, 74.989013671875, 77.26283264160156]\n",
            "\n",
            "Arxiv paper IDs: [29836, 100170, 353482, 1131386, 1442388, 1204467, 1007661, 1138352, 969530, 407092]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR0lUuDej8ut",
        "outputId": "c1368863-9604-4cb6-ba2f-4813491453d9"
      },
      "source": [
        "# Fetching the paper titles based on their index\n",
        "id2details(ai_ml_df, I, 'clean_title')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['An efficient reduction of ranking to classification'],\n",
              " ['The Offset Tree for Learning with Partial Labels'],\n",
              " ['Surrogate Regret Bounds for Bipartite Ranking via Strongly Proper Losses'],\n",
              " ['Equipping Experts/Bandits with Long-term Memory'],\n",
              " ['Adaptive Importance Sampling for Finite-Sum Optimization and Sampling   with Decreasing Step-Sizes'],\n",
              " ['A Reduction from Reinforcement Learning to No-Regret Online Learning'],\n",
              " ['Acceleration through Optimistic No-Regret Dynamics'],\n",
              " ['Online Active Learning of Reject Option Classifiers'],\n",
              " ['Online Improper Learning with an Approximation Oracle'],\n",
              " ['Adaptive Metric Dimensionality Reduction']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y892IGXZlBoj"
      },
      "source": [
        "# Define project base directory\n",
        "# Change the index from 1 to 0 if you run this on Google Colab\n",
        "# Serialise index and store it as a pickle\n",
        "with open(\"/content/gdrive/MyDrive/Arxiv/faiss_index_aiml.pickle\", \"wb\") as h:\n",
        "    pickle.dump(faiss.serialize_index(index), h)"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}